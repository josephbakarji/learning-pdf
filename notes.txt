
TO DO:

    - Generate new examples
        - Try simple case with known solution.
        - u0(x) has to have compact support!
        - Replace example by something more complicated: g(u), get analytical result if possible?
    - Test why it's not working for multiple IC
    - Learn Integro-differentil equation
    - Use 

Presentation:
    - Progression:  
        - PDF method definition (1 slide)
        - simple (reaction) example with solution (1 slide)
        - simple (advection) example with solution (1 slide)? 
        - apply it to compaction problem and show closures (3 slides)

        - Sparse identification of PDF equations (General) (2 slides)

        Results:
            - Apply it to reaction problem with known PDF equation (results)
            - Apply it to conservative form of reaction equation

            - Apply to marginal advection problem with unknown PDF equation
            - Compare with and without variable coefficients

            - Learn localized Integral term
            - Use Monte Carlo?

-----------------------------------------------------------

Paper:

    - Generate new examples
        - u0(x) has to have compact support!
        - Replace example by something more complicated: g(u), get analytical result if possible?
        - Try simple case with known solution.

    - Check for conservative equation for PDF. (see Mtalba's paper)
    - Constrain PDF equation in Problem definition more explicitely in conservative form.
        - Test errors by actually solving resulting PDE

    - Discussion
        - Add discussion about why our method is better.
        - Add variable coefficients results and paper

    - Results:
        - Generalize in time
            - Test on gradually farther portions of time.
            - Now time_general measures error as a function of training set size
        - Coefficient as a funciton of lambda
        - Sensitivity analysis
        - Error as a function of number of terms
        - Generalization tests: error as a function of training/test generality
        - Predictive ability vs. parsimony (as done in lipson's paper)
        
-----------------------------------

    - function for learning from that set 
        - Learn sequentially or use whole matrix (second is memory intensive)

    
    - Get Results:
        - Test impact of range on variable coefficient
        - Evaluate errors
            - analyze distribution of errors AND distribution of derivatives: we want the derivatives to be equaly represented
            - error should be dependent on increments dU, dx, and dt. Quantify order of error
        - Plot histogram comparing results of various combinations of properties

    - Algorithm Improvements:
        - Improve derivatives: Implement total variation regularized derivative
        - Include integral term in features
        - Fix partialfit() incomplete! 

    - Vizualization:
        - print features: write function makeFeatureNames (includes ^{01} -> 1*x)
            - tabulate printed values 
        - fix vizualization module

    - Test cases:
        - Try simple reaction case: du/dt = ku
        - Test on 5-equation model
    
    - Make online documentations

Some more improvements:
    - Code:
        - Optimize makefeatures function options (too redundant)
        - Unify test cases files
        - Try partial_fit()

    - Method:
        - Compute derivatives analytically for better estimate of accuaracy
        - Learn nonlocal terms (integrals)

	- Visualization: 
		- Unify 2D plots (plot_flabel and plot_fu, x and t)
		- make global self.slider list and append sliders to it to avoid conflicts


-----------------------------------------------------------
Issues And Discussion:

    - Storage:
        - Store in JSON format from dictionary in separate file
        - Metadata to include:
            - filename: keep the same?
            - discretization size (or number of grid points)
            - number of dimensions
            - ranges 
            - fu0_distribution: gaussian, uniform
                - parameters: (mean, variance) for gaussian, (xmin, xmax) for uniform etc.
            - fk_distribution: gaussian, uniform
                - parameters: (mean, variance) for gaussian, (xmin, xmax) for uniform etc.
            - u0: line, exp, sine etc.
                - parameters: (a, b) for ax+b if line, (a, b) for a*exp(bx) exp, etc. 

    - Robustness Analysis
        - The robustness (and thus generalizability) of the method depends on the distribution of the derivatives being all equally represented. 
        - If a stencil set of elements is the same, it's technically a redundant training example.

    - Code Issues:
        - Error doesn't change dramatically for a zero closure term.
        - Closure term fluctuates around zero when plotted
        - Error increases with T (training set size) for u0 exponential - Could be due to high nonlinearity at larger times.
        - What's the difference between score and error? 

    - Method:
        - The solution domain should contain the whole PDF to learn better: this could be computationally expensive 
        - A small error in the coefficient will cause a large one when integrated.

-------------------------------------------------------------


New Ideas:
    - Learn the dynamics (equation) of a kinetic defect f(x, t) in the case of shocks.
    - Learn integrator using neural network.
